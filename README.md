
# ğŸ¬ğŸğŸ“¶ Movie Recommendation System 

This project was created as part of the MLOps bootcamp (Sep24) ğŸ› ğŸ‘·ğŸ»â€â™‚ï¸. The project was used to try out different tools that can be used to deploy ML projects.


## ğŸ’» Developer Team:
- Asma Heena Khalil
- Ringo Schwabe 
- Carolin Stolpe ([@castolpe](https://github.com/castolpe))

## Business Objectives

The Movie Recommendation application addresses the challenge of providing personalized movie recommendations to users on a streaming platform. By leveraging collaborative filtering techniques, it enhances the user experience by suggesting movies that align with individual tastes. Sponsored by a streaming service, the project aims to improve user engagement and satisfaction through tailored content.

## App Architecture

## File structure
```
â”œâ”€â”€ .dvc                     <- Configuration of the data version control
â”œâ”€â”€ .github
â”‚Â Â  â””â”€â”€ workflows            <- Github Actions to trigger CI/CD pipeline and data pipeline 
â”‚ 
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ interim              <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed            <- The final, canonical data sets for modeling.
â”‚   â”œâ”€â”€ raw                  <- The original, immutable data dump.
â”‚Â Â  â””â”€â”€ status.txt           <- Indicator, if current data is valid.
â”‚
â”œâ”€â”€ logs                     <- Logs from training and predicting
â”‚
â”œâ”€â”€ metrics                  <- Metrics from the evaluated model.
â”‚ 
â”œâ”€â”€ models                   <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ monitoring               <- All files related to the monitoring of the application.
â”‚   â”œâ”€â”€ alertmanager         <- Configuration of the alert manager to inform in the event of deviations. 
â”‚   â”œâ”€â”€ grafana              <- Configuration of the Grafana dashboard to visualize the metrics collected by Prometheus.
â”‚Â Â  â””â”€â”€ prometheues          <- Configuration to collect metrics about the health status of the app, number of requests etc.
â”‚
â”œâ”€â”€ notebooks                <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                               the creator's initials, and a short `-` delimited description, e.g.
â”‚                               `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ references               <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports                  <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚Â Â  â””â”€â”€ figures              <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ src                      <- Source code for use in this project.
â”‚   â”œâ”€â”€ api                  <- Definiton of API endpoints
â”‚   â”œâ”€â”€ data_module_def      <- Scripts to download, validate and transform data
â”‚   â”œâ”€â”€ models_module_def    <- Scripts to train models and then use trained models to make
â”‚   â”‚                           predictions
â”‚   â”œâ”€â”€ pipeline_steps       <- Scripts for the single pipeline_steps from data download to model evaluation
â”‚   â”œâ”€â”€ utils                <- Helper functions and other utils (e.g. logger)
â”‚   â”œâ”€â”€ visualization        <- Scripts to create exploratory and results oriented visualizations
â”‚Â Â  â”‚   â””â”€â”€ visualize.py
â”‚   â”œâ”€â”€ config_manager.py    <- Create configuration objects for each of the stages
â”‚   â”œâ”€â”€ config.py            <- Paths to the config files
â”‚   â”œâ”€â”€ config.yaml          <- Values for the required configuration fields 
â”‚Â Â  â””â”€â”€ entity.py            <- Definition of the config fields
â”‚   dvc.lock                 <- Locks of the last pipeline run
â”‚   dvc.yaml                 <- Orchestration of pipeline steps (DAG).
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                <- The top-level README for developers using this project.
â””â”€â”€ requirements.txt         <- The requirements file for reproducing the analysis environment, e.g.
                                generated with `pip freeze > requirements.txt`
```

## Getting Started

To run the app locally follow these steps:

### 1. Clone the project
```
git clone https://github.com/DataScientest-Studio/sep24_bmlops_int_reco_films.git
cd /sep24_bmlops_int_reco_films
```

### 2. Setup virtual environment & install dependencies
```
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Download data from remote storage
Data, metrics and models are stored on Dagshub Remote Storage using DVC. Make sure to download 
the data before running the app.
```
# Configure access to DVC
dvc remote modify origin --local access_key_id YOUR_DVC_ACCESS_KEY
dvc remote modify origin --local secret_access_key YOUR_DVC_ACCESS_KEY

# Pull the data
dvc pull
```

### 4. Build the Docker ğŸ³ container and launch the app
```
docker-compose up
```

### 5. Query the endpoints
```
# Check, if API is running
curl -X GET i http://0.0.0.0:8000/status

# Read the API docs
curl -X GET i http://0.0.0.0:8000/docs

# Get movie recommendation
curl -X 'POST' \
  'http://localhost:8000/users/recommendations' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "no_genres_listed": 0,
  "action": 0,
  "adventure": 0,
  "animation": 5,
  "children": 3,
  "comedy": 2,
  "crime": 0,
  "documentary": 0,
  "drama": 0,
  "fantasy": 0,
  "film_noir": 0,
  "horror": 0,
  "imax": 0,
  "musical": 0,
  "mystery": 0,
  "romance": 0,
  "sci_fi": 0,
  "thriller": 0,
  "war": 0,
  "western": 0
}'

```

### 6. Checkout the monitoring dashboard

â¡ Go to http://localhost:3000/d/_eX4mpl3/fastapi-dashboard in your web browser.
