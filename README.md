# ğŸ¬ğŸğŸ“¶ Movie Recommendation System 

This project was created as part of the MLOps bootcamp (Sep24) ğŸ› ğŸ‘·ğŸ»â€â™‚ï¸. The project demonstrates a comprehensive MLOps implementation for deploying and maintaining a movie recommendation system.

Project Repository: [Dagshub](https://dagshub.com/castolpe/sep24_bmlops_int_reco_films)

## ğŸ’» Developer Team:
- Asma Heena Khalil ([@asma484](https://github.com/asma484))
- Ringo Schwabe ([@roongi](https://github.com/roongi))
- Carolin Stolpe ([@castolpe](https://github.com/castolpe))

## Business Objectives

The Movie Recommendation application addresses the challenge of providing personalized movie recommendations to users on a streaming platform. By leveraging collaborative filtering techniques, it enhances the user experience by suggesting movies that align with individual tastes. Sponsored by a streaming service, the project aims to:

- Increase user engagement through personalized content recommendations
- Improve user retention by suggesting relevant movies
- Enhance content discovery across the platform's catalog
- Drive higher user satisfaction through accurate recommendations

## ğŸ”„ MLOps Workflow Overview

![MLOps Workflow Diagram](workflow_diagrams/mlops_workflow_latest.png)

> ğŸ“ View the [high-resolution SVG version](workflow_diagrams/mlops_workflow_latest.svg) for better detail.

### ğŸ¯ Detailed Pipeline Steps

Our MLOps pipeline consists of five major components, each handling specific aspects of the machine learning lifecycle:

#### 1ï¸âƒ£ CI/CD Pipeline (GitHub Actions) 
- â° **Scheduled Trigger**: Daily at midnight
- ğŸ“ˆ **Data Version Update**: Increments data version
- ğŸš€ **Pipeline Trigger**: Initiates DVC pipeline
- ğŸ“¤ **Main Branch Update**: Pushes changes
- ğŸ”„ **API Deployment**: Triggers new deployment (in progress ğŸš§)

#### 2ï¸âƒ£ DVC Pipeline (MLFlow/DVC)
- ğŸ“¥ **Data Ingestion**: Appends new data
- âœ… **Validation**: Ensures data quality
- ğŸ”„ **Transformation**: Prepares features
- ğŸ§  **Model Training**: Updates model
- ğŸ“Š **Evaluation**: Assesses performance

#### 3ï¸âƒ£ Experiment Monitoring
- ğŸ“š **MLFlow Registry**: Tracks experiments
- ğŸ’¾ **DVC Version Control**: Manages artifacts

#### 4ï¸âƒ£ Deployed Application
- ğŸ†• **API Updates**: New versions (ğŸš§)
- ğŸ‘¥ **User Interaction**: Real-time recommendations

#### 5ï¸âƒ£ Monitoring Stack
- ğŸ“ˆ **Metrics Collection**: Prometheus
- ğŸ“Š **Dashboard**: Grafana
- âš ï¸ **Alerts**: AlertManager (ğŸš§)

### ğŸ”„ Pipeline Interactions

1. **Data Update Cycle**
```mermaid
graph LR
    A[â° Cron Trigger] --> B[ğŸ“ˆ Update Version]
    B --> C[ğŸš€ Trigger Pipeline]
    C --> D[ğŸ“¥ Process Data]
    D --> E[ğŸ§  Train Model]
    E --> F[ğŸ“Š Evaluation]
```

2. **Deployment Cycle**
```mermaid
graph LR
    A[ğŸ“Š Evaluation] --> B[ğŸ“¤ Push Changes]
    B --> C[ğŸ”„ Deploy API]
    C --> D[ğŸ‘¥ Users]
    D --> E[ğŸ“ˆ Monitoring]
```

### ğŸ›  Component Details

#### 1. Data Pipeline & Version Control
```bash
# Data versioning workflow
â”œâ”€â”€ ğŸ“¥ Data Ingestion
â”œâ”€â”€ âœ… Validation
â”œâ”€â”€ ğŸ”„ Transformation
â”œâ”€â”€ ğŸ§  Training
â””â”€â”€ ğŸ“Š Evaluation
```

#### 2. Model Training & Deployment
```bash
# Model lifecycle
â”œâ”€â”€ ğŸ§ª Experiment Tracking (MLFlow)
â”œâ”€â”€ ğŸ“Š Performance Metrics
â”œâ”€â”€ ğŸ“¦ Containerization (Docker)
â””â”€â”€ ğŸš€ API Deployment (FastAPI)
```

#### 3. Monitoring & Alerts
```bash
# Monitoring stack
â”œâ”€â”€ ğŸ“ˆ Metrics (Prometheus)
â”œâ”€â”€ ğŸ“Š Visualization (Grafana)
â””â”€â”€ âš ï¸ Alerting (AlertManager)
```

### ğŸ” Workflow Deep Dive

#### 1. Data Update Process
1. â° **Trigger**: Daily at midnight
2. ğŸ“ˆ **Version Update**: Increment data version
3. ğŸš€ **Pipeline Start**: Trigger DVC pipeline
4. ğŸ“¥ **Data Processing**: Execute pipeline stages
5. ğŸ“Š **Validation**: Ensure quality metrics

#### 2. Model Training Cycle
1. ğŸ§  **Training**: Update model with new data
2. ğŸ“Š **Evaluation**: Calculate performance metrics
3. ğŸ“š **Registry**: Record in MLFlow
4. ğŸ’¾ **Versioning**: Save with DVC
5. ğŸ“¤ **Push**: Update main branch

#### 3. Deployment Process
1. ğŸ”„ **Trigger**: New model version available
2. ğŸ“¦ **Container**: Build new Docker image and push to Docker Hub
3. ğŸš€ **Deploy**: Update API service (ğŸš§)
4. ğŸ‘¥ **Users**: Serve new predictions
5. ğŸ“ˆ **Monitor**: Track performance

### ğŸ“Š Monitoring & Feedback

#### Real-time Metrics
- ğŸ” **API Performance**
  - Response times
  - Request volumes
  - Error rates

- ğŸ“ˆ **Model Metrics**
  - Prediction accuracy
  - Processing time
  - Resource usage

- âš ï¸ **Alerts**
  - Performance degradation
  - Error thresholds
  - Resource constraints

## Technical Architecture

### Data Flow
1. Raw data ingestion (`data/raw/`)
2. Data preprocessing (`data/interim/`)
3. Feature engineering (`data/processed/`)
4. Model training (`models/`)
5. API deployment

### Component Structure
```
src/
â”œâ”€â”€ api/                    # FastAPI implementation
â”œâ”€â”€ data_module_def/        # Data processing modules
â”œâ”€â”€ models_module_def/      # Model definition and training
â”œâ”€â”€ pipeline_steps/         # DVC pipeline stages
â””â”€â”€ utils/                  # Helper functions
```

## Getting Started

### 1. Clone the project
```bash
git clone https://github.com/DataScientest-Studio/sep24_bmlops_int_reco_films.git
cd /sep24_bmlops_int_reco_films
```

### 2. Setup virtual environment & install dependencies
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Configure DVC and download data
```bash
# Configure access to DVC
dvc remote modify origin --local access_key_id YOUR_DVC_ACCESS_KEY
dvc remote modify origin --local secret_access_key YOUR_DVC_ACCESS_KEY

# Pull the data
dvc pull
```

### 4. Launch the application
```bash
docker-compose up
```

### 5. API Usage

#### Health Check
```bash
curl -X GET http://0.0.0.0:8000/status
```

#### Get Recommendations
```bash
curl -X 'POST' \
  'http://localhost:8000/users/recommendations' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "animation": 5,
  "children": 3,
  "comedy": 2,
  // ... other genre preferences
}'
```

### 6. Monitoring Dashboard

Access the Grafana dashboard at: http://localhost:3000/d/_eX4mpl3/fastapi-dashboard

## ğŸš€ Future Improvementes

The next steps we want to implement in the project:

- [ ] Enhance CI/CD Pipeline and automate deploymentğŸ”„
- [ ] Improve machine learning model ğŸ§ 
- [ ] Implement user feedback system ğŸŒ
- [ ] Use Airflow for pipeline orchestration ğŸ› 
- [ ] Implement Kubernetes deployment (scalability) ğŸ› 
- [ ] Implement alertmanager for drift detection ğŸ“Š
- [ ] Add testing suite ğŸ”
- [ ] Enhance API security by adding OAuth2 authentication ğŸ”

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
