import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List
from sklearn.feature_selection import mutual_info_regression

def analyze_user_feedback(feedback_path: str) -> Dict[str, int]:
    """
    Analyze user feedback and return counts of positive and negative feedback.
    
    Args:
    feedback_path (str): Path to the CSV file containing user feedback.
    
    Returns:
    Dict[str, int]: Dictionary containing counts of positive and negative feedback.
    """
    feedback = pd.read_csv(feedback_path)
    positive_feedback = feedback[feedback['rating'] >= 4].shape[0]
    negative_feedback = feedback[feedback['rating'] < 4].shape[0]
    return {'positive': positive_feedback, 'negative': negative_feedback}

def plot_feedback_distribution(feedback_counts: Dict[str, int]) -> None:
    """
    Plot the distribution of user feedback.
    
    Args:
    feedback_counts (Dict[str, int]): Dictionary containing counts of positive and negative feedback.
    """
    plt.figure(figsize=(8, 6))
    plt.bar(feedback_counts.keys(), feedback_counts.values())
    plt.title('User Feedback Distribution')
    plt.xlabel('Feedback Type')
    plt.ylabel('Count')
    plt.show()

def detect_data_drift(old_data_path: str, new_data_path: str, threshold: float = 0.1) -> List[str]:
    """
    Detect data drift between old and new datasets.
    
    Args:
    old_data_path (str): Path to the CSV file containing old data.
    new_data_path (str): Path to the CSV file containing new data.
    threshold (float): Threshold for considering a feature as drifted.
    
    Returns:
    List[str]: List of features that have drifted.
    """
    old_data = pd.read_csv(old_data_path)
    new_data = pd.read_csv(new_data_path)
    
    drifted_features = []
    for column in old_data.columns:
        if old_data[column].dtype in ['int64', 'float64']:
            old_mean, old_std = old_data[column].mean(), old_data[column].std()
            new_mean, new_std = new_data[column].mean(), new_data[column].std()
            
            if abs(old_mean - new_mean) > threshold * old_std:
                drifted_features.append(column)
    
    return drifted_features

def analyze_feature_importance(data_path: str, target_column: str) -> pd.DataFrame:
    """
    Analyze feature importance using mutual information.
    
    Args:
    data_path (str): Path to the CSV file containing the dataset.
    target_column (str): Name of the target column.
    
    Returns:
    pd.DataFrame: DataFrame containing feature importance scores.
    """
    data = pd.read_csv(data_path)
    X = data.drop(columns=[target_column])
    y = data[target_column]
    
    mi_scores = mutual_info_regression(X, y)
    mi_scores = pd.DataFrame({'feature': X.columns, 'importance': mi_scores})
    mi_scores = mi_scores.sort_values('importance', ascending=False)
    
    return mi_scores

def main():
    # Example usage
    feedback_counts = analyze_user_feedback('path/to/feedback.csv')
    plot_feedback_distribution(feedback_counts)
    
    drifted_features = detect_data_drift('path/to/old_data.csv', 'path/to/new_data.csv')
    print("Drifted features:", drifted_features)
    
    feature_importance = analyze_feature_importance('path/to/dataset.csv', 'target_column')
    print("Top 10 important features:")
    print(feature_importance.head(10))

if __name__ == "__main__":
    main()
